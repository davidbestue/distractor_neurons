{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "## Functions needed\n",
    "\n",
    "def pos_xy_to_angle(x, y):\n",
    "    deg = np.degrees(np.arctan2(y,x))\n",
    "    if deg<0:\n",
    "        deg=360-abs(deg)\n",
    "    \n",
    "    deg=int(deg)\n",
    "    return deg\n",
    "\n",
    "\n",
    "\n",
    "def RFangle_2_octaves(angle):\n",
    "    ## round RF to octave\n",
    "    value = min([0, 45, 90, 135, 180, 225, 270, 315, 360], key=lambda x:abs(x-angle))\n",
    "    \n",
    "    if value==360:\n",
    "        value=0\n",
    "    \n",
    "    return value\n",
    "\n",
    "\n",
    "RFangle_2_octaves(329)    \n",
    "\n",
    "def angle_from_RF(loc_angle, RF_angle):\n",
    "    ## change from position of target to angle taking into account the RF\n",
    "    angle_target = RFangle_2_octaves(RF_angle)\n",
    "    angle_dist = angle_target + 45*loc_angle\n",
    "    if angle_dist>=360:\n",
    "        angle_dist=angle_dist-360\n",
    "    \n",
    "    if loc_angle==99:\n",
    "        angle_dist=np.nan\n",
    "    \n",
    "    return angle_dist\n",
    "\n",
    "\n",
    "# x_rf=f['data']['info'][0][0][0][1][0][25][0][0]\n",
    "# y_rf=f['data']['info'][0][0][0][1][0][26][0][0]\n",
    "\n",
    "# RF_angle = pos_xy_to_angle(x_rf, y_rf)\n",
    "# RF_loc = RFangle_2_octaves(RF_angle)\n",
    "\n",
    "\n",
    "# Dist_loc = angle_from_RF(99, RF_loc)\n",
    "\n",
    "# print(RF_angle, RF_loc, Dist_loc)\n",
    "def RFangle_2_octaves(angle):\n",
    "    ## round RF to octave\n",
    "    value = min([0, 45, 90, 135, 180, 225, 270, 315, 360], key=lambda x:abs(x-angle))\n",
    "    \n",
    "    if value==360:\n",
    "        value=0\n",
    "    \n",
    "    return value\n",
    "\n",
    "\n",
    "def circdist(a1,a2):\n",
    "    ## Returns the minimal distance in angles between to angles \n",
    "    op1=abs(a2-a1)\n",
    "    angs=[a1,a2]\n",
    "    op2=min(angs)+(360-max(angs))\n",
    "    options=[op1,op2]\n",
    "    return min(options)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons = 104\n",
      "Speriatus 0\n",
      "189139306.mat\n",
      "Trials keep = 416\n",
      "Trials excluded = 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speriatus 1\n",
      "1891406.mat\n",
      "Trials keep = 508\n",
      "Trials excluded = 18\n",
      "Speriatus 2\n",
      "1891407.mat\n",
      "Trials keep = 472\n",
      "Trials excluded = 86\n",
      "Speriatus 3\n",
      "189141804.mat\n",
      "Trials keep = 307\n",
      "Trials excluded = 43\n",
      "Speriatus 4\n",
      "1891421.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 27\n",
      "Speriatus 5\n",
      "1891436.mat\n",
      "Trials keep = 477\n",
      "Trials excluded = 89\n",
      "Speriatus 6\n",
      "189144701.mat\n",
      "Trials keep = 505\n",
      "Trials excluded = 33\n",
      "Speriatus 7\n",
      "189144904.mat\n",
      "Trials keep = 485\n",
      "Trials excluded = 51\n",
      "Speriatus 8\n",
      "189147105.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 111\n",
      "Speriatus 9\n",
      "189150602.mat\n",
      "Trials keep = 471\n",
      "Trials excluded = 91\n",
      "Speriatus 10\n",
      "189151102.mat\n",
      "Trials keep = 472\n",
      "Trials excluded = 12\n",
      "Speriatus 11\n",
      "189152601.mat\n",
      "Trials keep = 465\n",
      "Trials excluded = 43\n",
      "Speriatus 12\n",
      "189154404.mat\n",
      "Trials keep = 479\n",
      "Trials excluded = 17\n",
      "Speriatus 13\n",
      "189154602.mat\n",
      "Trials keep = 482\n",
      "Trials excluded = 33\n",
      "Speriatus 14\n",
      "189155501.mat\n",
      "Trials keep = 498\n",
      "Trials excluded = 172\n",
      "Speriatus 15\n",
      "189156205.mat\n",
      "Trials keep = 482\n",
      "Trials excluded = 66\n",
      "Speriatus 16\n",
      "189157901.mat\n",
      "Trials keep = 460\n",
      "Trials excluded = 80\n",
      "Speriatus 17\n",
      "189158601.mat\n",
      "Trials keep = 520\n",
      "Trials excluded = 152\n",
      "Speriatus 18\n",
      "1891598.mat\n",
      "Trials keep = 477\n",
      "Trials excluded = 15\n",
      "Speriatus 19\n",
      "189160302.mat\n",
      "Trials keep = 485\n",
      "Trials excluded = 33\n",
      "Speriatus 20\n",
      "189160702.mat\n",
      "Trials keep = 523\n",
      "Trials excluded = 25\n",
      "Speriatus 21\n",
      "189161604.mat\n",
      "Trials keep = 459\n",
      "Trials excluded = 101\n",
      "Speriatus 22\n",
      "1891626.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 58\n",
      "Speriatus 23\n",
      "189163101.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 85\n",
      "Speriatus 24\n",
      "189163701.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 118\n",
      "Speriatus 25\n",
      "189164103.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 84\n",
      "Speriatus 26\n",
      "189164404.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 74\n",
      "Speriatus 27\n",
      "189164801.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 83\n",
      "Speriatus 28\n",
      "189164803.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 83\n",
      "Speriatus 29\n",
      "189165003.mat\n",
      "Trials keep = 458\n",
      "Trials excluded = 44\n",
      "Speriatus 30\n",
      "1891653.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 206\n",
      "Speriatus 31\n",
      "189168701.mat\n",
      "Trials keep = 465\n",
      "Trials excluded = 15\n",
      "Speriatus 32\n",
      "189169502.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 50\n",
      "Speriatus 33\n",
      "189171003.mat\n",
      "Trials keep = 481\n",
      "Trials excluded = 39\n",
      "Speriatus 34\n",
      "189171602.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 167\n",
      "Speriatus 35\n",
      "189172801.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 55\n",
      "Speriatus 36\n",
      "189173101.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 65\n",
      "Speriatus 37\n",
      "189173801.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 69\n",
      "Speriatus 38\n",
      "189174201.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 101\n",
      "Speriatus 39\n",
      "189175201.mat\n",
      "Trials keep = 462\n",
      "Trials excluded = 80\n",
      "Speriatus 40\n",
      "189175801.mat\n",
      "Trials keep = 467\n",
      "Trials excluded = 105\n",
      "Speriatus 41\n",
      "189176101.mat\n",
      "Trials keep = 461\n",
      "Trials excluded = 87\n",
      "Speriatus 42\n",
      "189176501.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 103\n",
      "Speriatus 43\n",
      "189176901.mat\n",
      "Trials keep = 505\n",
      "Trials excluded = 38\n",
      "Speriatus 44\n",
      "189177402.mat\n",
      "Trials keep = 476\n",
      "Trials excluded = 53\n",
      "Speriatus 45\n",
      "189177701.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 75\n",
      "Speriatus 46\n",
      "1891783.mat\n",
      "Trials keep = 509\n",
      "Trials excluded = 61\n",
      "Speriatus 47\n",
      "189179001.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 33\n",
      "Speriatus 48\n",
      "189179002.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 33\n",
      "Speriatus 49\n",
      "1891793.mat\n",
      "Trials keep = 508\n",
      "Trials excluded = 32\n",
      "Speriatus 50\n",
      "189179702.mat\n",
      "Trials keep = 458\n",
      "Trials excluded = 65\n",
      "Speriatus 51\n",
      "189180001.mat\n",
      "Trials keep = 509\n",
      "Trials excluded = 41\n",
      "Speriatus 52\n",
      "189181001.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 61\n",
      "Speriatus 53\n",
      "189181502.mat\n",
      "Trials keep = 500\n",
      "Trials excluded = 120\n",
      "Speriatus 54\n",
      "1891819.mat\n",
      "Trials keep = 460\n",
      "Trials excluded = 76\n",
      "Speriatus 55\n",
      "189182202.mat\n",
      "Trials keep = 506\n",
      "Trials excluded = 38\n",
      "Speriatus 56\n",
      "189182501.mat\n",
      "Trials keep = 506\n",
      "Trials excluded = 114\n",
      "Speriatus 57\n",
      "189182901.mat\n",
      "Trials keep = 507\n",
      "Trials excluded = 131\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#path='C:\\\\Users\\\\David\\\\Desktop\\\\IDIBAPS\\\\Gottlib_data\\\\data files\\\\distractor paper data only\\\\Mojo'\n",
    "\n",
    "for monkey_directory in ['Speriatus', 'Mojo']:\n",
    "    path = 'C:\\\\Users\\\\David\\\\Desktop\\\\IDIBAPS\\\\Gottlib_data\\\\data files\\\\distractor paper data only\\\\' +monkey_directory\n",
    "    #path='C:\\\\Users\\\\David\\\\Desktop\\\\IDIBAPS\\\\Gottlib_data\\\\data files\\\\distractor paper data only\\\\'+monkey_directory\n",
    "    os.chdir(path)\n",
    "    Monkey = path.split('\\\\')[-1]\n",
    "    print('Number of neurons = ' + str(len(os.listdir())))\n",
    "\n",
    "    for file_to_use in range(0, len(os.listdir()) ):  #\n",
    "        os.chdir(path)\n",
    "        print(  monkey_directory + ' ' + str(file_to_use))\n",
    "        file_numb=file_to_use\n",
    "        file = os.listdir()[file_numb]\n",
    "        print(file)\n",
    "        # import file into a dictionary\n",
    "        f = scipy.io.loadmat(file)\n",
    "        #\n",
    "        ## Get the RF features\n",
    "        x_rf=f['data']['info'][0][0][0][1][0][25][0][0]\n",
    "        y_rf=f['data']['info'][0][0][0][1][0][26][0][0]\n",
    "        RF_angle = pos_xy_to_angle(x_rf, y_rf)\n",
    "        RF_loc = RFangle_2_octaves(RF_angle)\n",
    "\n",
    "        np.shape(f['data']['spikes'][0][0][0])\n",
    "\n",
    "        #Continue if data\n",
    "\n",
    "        if np.shape(f['data']['spikes'][0][0][0]) ==(0,):\n",
    "            print('No data')\n",
    "            #break()\n",
    "\n",
    "        else:        \n",
    "            #Spikes times\n",
    "            df_spike_time=pd.DataFrame(f['data']['spikes'][0][0][0][0][:, :])\n",
    "            np.shape(df_spike_time)\n",
    "            df_spike_time.iloc[:, 0]\n",
    "            df_spike_time.columns = [str(i) for i in range(0, np.shape(df_spike_time)[1])]\n",
    "\n",
    "\n",
    "            ### Events\n",
    "            Dict_events={}\n",
    "\n",
    "            for i in range(0, len(f['data']['events'][0][0][0])     ):\n",
    "                events = pd.DataFrame( f['data']['events'][0][0][0][i])\n",
    "                events.columns=['time', 'code']\n",
    "                Dict_events[str(i)]= events\n",
    "\n",
    "\n",
    "            ### Descriptors & Bad trials\n",
    "            ## Use the Descriptors to take the booleans to use\n",
    "            lists=[]\n",
    "            for T in range(0, len(f['data']['descriptors'][0][0][0])):\n",
    "                lists.append( [f['data']['descriptors'][0][0][0][T][i][0] for i in range(len(f['data']['descriptors'][0][0][0][T]) )] )\n",
    "\n",
    "\n",
    "\n",
    "            #\n",
    "            Descriptors = pd.DataFrame(lists)\n",
    "            Descriptors=Descriptors.transpose()\n",
    "            Descriptors.columns = [str(i) for i in range(0, np.shape(Descriptors)[1])]\n",
    "\n",
    "            ## 26 descriptot for each trial\n",
    "            # 6 = 1 for success, 14== antisacade, 15==othersacade\n",
    "            boolean_success_trials = Descriptors.iloc[6].isin([1, 14, 15]) #Descriptors.iloc[6,:]==1\n",
    "\n",
    "            # 24  0, 1, 2 for target in RF \n",
    "            #boolean_TinRF_trials = Descriptors.iloc[24].isin([0,1,2])\n",
    "\n",
    "            ##Use the bad to take the booleans of bad trials\n",
    "            #Bad trials\n",
    "            bad = pd.DataFrame(np.array([f['data']['bad'][0][0][0][x][0][0] for x in range(0, len(f['data']['bad'][0][0][0]))]))\n",
    "            bad = bad.transpose()\n",
    "            bad.columns = [str(i) for i in range(0, np.shape(df_spike_time)[1])]\n",
    "\n",
    "            #print(shape(bad))\n",
    "            #each column in a trial; if 1, discard it\n",
    "            boolean_correct_trials = bad.iloc[0,:]!=1\n",
    "\n",
    "\n",
    "\n",
    "            #Boolean combinging success trials and correct\n",
    "            boolean_keep = boolean_success_trials & boolean_correct_trials \n",
    "            print('Trials keep = ' +str(sum(boolean_keep)))\n",
    "            print('Trials excluded = ' + str(np.shape(df_spike_time)[1] - sum(boolean_keep) ))\n",
    "\n",
    "            #df_spikes_correct\n",
    "            indexes_trials_keep = np.array([str(i) for i in range(0, np.shape(df_spike_time)[1])])[boolean_keep]\n",
    "            df_spikes = df_spike_time[list(indexes_trials_keep)]\n",
    "            df_spikes = df_spikes.iloc[4:, :]\n",
    "            #take off columns full of nans (after the first 4, the rest was nan)\n",
    "            df_spikes = df_spikes.transpose()[df_spikes.iloc[0,:]<9999].transpose() \n",
    "\n",
    "\n",
    "\n",
    "            #\n",
    "            ### Convert the df_spikes to count_spikes\n",
    "            def count_spikes(data, start=0, wind=100):\n",
    "                max_value = int(data[data<9999].max())\n",
    "                windows = np.arange(start, max_value, wind)\n",
    "\n",
    "                counts=[]\n",
    "\n",
    "                for idx, w in enumerate(list(windows)[:-1]):\n",
    "                    counts.append(sum((data>w) & (data<windows[idx+1])))\n",
    "\n",
    "                return counts\n",
    "\n",
    "\n",
    "            ## Not all the trials are equally long. Windows starting at the target onset\n",
    "            number_count=[]\n",
    "            for TRIAL in list(df_spikes.columns):\n",
    "                try:\n",
    "                    target_onset = Dict_events[TRIAL].loc[Dict_events[TRIAL]['code']==6, 'time'].values[0]\n",
    "                except IndexError:\n",
    "                    try:\n",
    "                        target_onset = Dict_events[TRIAL].loc[Dict_events[TRIAL]['code']==7, 'time'].values[0] -100\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "\n",
    "                ####\n",
    "                spike_count_column = count_spikes(df_spikes[TRIAL],start=target_onset-400, wind=100)\n",
    "                #### you need to have the max len for the next matrix\n",
    "                number_count.append(len(spike_count_column))\n",
    "\n",
    "\n",
    "\n",
    "            ### Dataframe with the spike count in the windows \n",
    "            df_count = pd.DataFrame(np.nan, index=list(range(0, max(number_count))) , columns=list(df_spikes.columns))\n",
    "\n",
    "            for TRIAL in list(df_spikes.columns):    \n",
    "                try:\n",
    "                    target_onset = Dict_events[TRIAL].loc[Dict_events[TRIAL]['code']==6, 'time'].values[0]\n",
    "                    spike_count_column = count_spikes(df_spikes[TRIAL], start=target_onset -400, wind=100)\n",
    "                    df_count[TRIAL].iloc[0:len(spike_count_column)] = spike_count_column\n",
    "                except IndexError:\n",
    "                    try:\n",
    "                        target_onset = Dict_events[TRIAL].loc[Dict_events[TRIAL]['code']==7, 'time'].values[0] -100\n",
    "                        spike_count_column = count_spikes(df_spikes[TRIAL], start=target_onset-400, wind=100)\n",
    "                        df_count[TRIAL].iloc[0:len(spike_count_column)] = spike_count_column\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                ####\n",
    "                #spike_count_column = count_spikes(df_spikes[TRIAL], start=target_onset, wind=100)\n",
    "                #df_count[TRIAL].iloc[0:len(spike_count_column)] = spike_count_column\n",
    "\n",
    "\n",
    "            #df_count\n",
    "\n",
    "\n",
    "            #Profile of a neuron rate (mean for window)\n",
    "            Matrix =df_count.transpose()\n",
    "            #Matrix\n",
    "            sns.pointplot(data=Matrix)\n",
    "\n",
    "\n",
    "            #(trials, times)\n",
    "            #np.shape(Matrix)\n",
    "            #os.chdir('C:\\\\Users\\\\David\\\\Desktop\\\\IDIBAPS\\\\Gottlib_data\\\\David fixation')\n",
    "            os.chdir('C:\\\\Users\\\\David\\\\Desktop\\\\IDIBAPS\\\\Gottlib_data\\\\firing_rates')\n",
    "\n",
    "            #Dictionary to save\n",
    "            Matrix_events={}\n",
    "            name_dict = file.split('.')[0]\n",
    "\n",
    "            TRIALS = {}\n",
    "            for i in list(Matrix.index):\n",
    "                TRIALS[i] = Dict_events[i]\n",
    "\n",
    "            Matrix_events['data'] = Matrix\n",
    "            Matrix_events['monkey'] = Monkey\n",
    "            Matrix_events['trials'] =TRIALS\n",
    "            #### Descriptors\n",
    "            Descriptors_use = Descriptors[list(Matrix_events['trials'].keys())]\n",
    "            Targets_locations = Descriptors_use.loc[1].values\n",
    "            Targets_loc = [angle_from_RF(t, RF_loc) for t in Targets_locations]\n",
    "            Descriptors_use.loc[26]=RF_angle #### the specific RF angle (0, 360 of the target)\n",
    "            Descriptors_use.loc[27]=RF_loc  ##### the RF loc of the target (0, 45, 90, 135...)\n",
    "            Descriptors_use.loc[28]=Targets_loc  ### the real angle of the target (0,45,90.....)\n",
    "\n",
    "            Distractors_locations = Descriptors_use.loc[19].values\n",
    "            Distractors_loc = [angle_from_RF(d, RF_loc) for d in Distractors_locations]\n",
    "            Descriptors_use.loc[29]=Distractors_loc #### the real angle of the distractor (0, 45, 90...)\n",
    "\n",
    "\n",
    "            Centered_target = [circdist(Descriptors_use.loc[27][i], Descriptors_use.loc[28][i]) for i in range(0, len(Descriptors_use.loc[28]))]\n",
    "            Descriptors_use.loc[30]=Centered_target\n",
    "\n",
    "            target_180_180 = Descriptors_use.loc[28] - Descriptors_use.loc[27]\n",
    "            for n in range(0, len(target_180_180)):\n",
    "                if target_180_180[n] >180:\n",
    "                    target_180_180[n]= target_180_180[n]-360\n",
    "\n",
    "\n",
    "            Descriptors_use.loc[31]=target_180_180\n",
    "\n",
    "            real_target_loc = Descriptors_use.loc[27] + Descriptors_use.loc[31]\n",
    "\n",
    "            ##### real_target_loc\n",
    "            for i in range(0, len(real_target_loc)):\n",
    "                if real_target_loc[i]<0:\n",
    "                    real_target_loc[i] = 360 + real_target_loc[i]\n",
    "\n",
    "\n",
    "            Descriptors_use.loc[32] = real_target_loc\n",
    "            ###\n",
    "            Matrix_events['Descriptor'] =Descriptors_use\n",
    "            \n",
    "            ####\n",
    "            #### Normalized firing rate\n",
    "            #Trials_norm_FR = Matrix_events['Descriptor'].columns[(Matrix_events['Descriptor'].loc[20]==0) & (Matrix_events['Descriptor'].loc[24]==0)] ## distractors of 0ms\n",
    "            Trials_norm_FR = Matrix_events['Descriptor'].columns[Matrix_events['Descriptor'].loc[19]==99] ##the no distractors\n",
    "            FR_cont = Matrix_events['data'].loc[Trials_norm_FR]\n",
    "            #max_fr = FR_cont.max().max()\n",
    "            max_fr = FR_cont.mean()\n",
    "            Matrix_events['data_norm'] = Matrix_events['data']/max_fr\n",
    "\n",
    "            ### Save\n",
    "            np.save( name_dict + '.npy', Matrix_events) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
