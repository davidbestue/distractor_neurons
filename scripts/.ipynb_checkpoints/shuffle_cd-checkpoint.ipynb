{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle in the Cross-decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all dictionaries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dictionaries\n",
    "#%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "##if you are the local\n",
    "#os.chdir('C:\\\\Users\\\\David\\\\Dropbox\\\\IDIBAPS\\\\Distractor_neurons\\\\FR_trials') #David_all_cond\n",
    "\n",
    "## if your are in the cluster\n",
    "os.chdir('/home/david/Desktop/IDIBAPS/Gottlib/FR_trials')\n",
    "\n",
    "\n",
    "\n",
    "##Load the data\n",
    "### Target\n",
    "LIP_control = np.load('control_LIP.npy')\n",
    "LIP_0 = np.load('0_LIP.npy')\n",
    "LIP_100 = np.load('100_LIP.npy')\n",
    "LIP_200 = np.load('200_LIP.npy')\n",
    "LIP_800 = np.load('800_LIP.npy')\n",
    "####\n",
    "DLPFC_control = np.load('control_DLPFC.npy')\n",
    "DLPFC_0 = np.load('0_DLPFC.npy')\n",
    "DLPFC_100 = np.load('100_DLPFC.npy')\n",
    "DLPFC_200 = np.load('200_DLPFC.npy')\n",
    "DLPFC_800 = np.load('800_DLPFC.npy')\n",
    "\n",
    "### Distractor\n",
    "LIP_control_d = np.load('control_LIP_d.npy')\n",
    "LIP_0_d = np.load('0_LIP_d.npy')\n",
    "LIP_100_d = np.load('100_LIP_d.npy')\n",
    "LIP_200_d = np.load('200_LIP_d.npy')\n",
    "LIP_800_d = np.load('800_LIP_d.npy')\n",
    "####\n",
    "DLPFC_control_d = np.load('control_DLPFC_d.npy')\n",
    "DLPFC_0_d = np.load('0_DLPFC_d.npy')\n",
    "DLPFC_100_d = np.load('100_DLPFC_d.npy')\n",
    "DLPFC_200_d = np.load('200_DLPFC_d.npy')\n",
    "DLPFC_800_d = np.load('800_DLPFC_d.npy')\n",
    "\n",
    "### Response\n",
    "LIP_control_r = np.load('control_LIP_r.npy')\n",
    "LIP_0_r = np.load('0_LIP_r.npy')\n",
    "LIP_100_r = np.load('100_LIP_r.npy')\n",
    "LIP_200_r = np.load('200_LIP_r.npy')\n",
    "LIP_800_r = np.load('800_LIP_r.npy')\n",
    "####\n",
    "DLPFC_control_r = np.load('control_DLPFC_r.npy')\n",
    "DLPFC_0_r = np.load('0_DLPFC_r.npy')\n",
    "DLPFC_100_r = np.load('100_DLPFC_r.npy')\n",
    "DLPFC_200_r = np.load('200_DLPFC_r.npy')\n",
    "DLPFC_800_r = np.load('800_DLPFC_r.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Cross-decoder of Target\n",
    "\n",
    "#### The labels are rolled N+1 100 times\n",
    "#### One value for time and condition\n",
    "#### For each condition, I make 100 decodings of the target in all the time points.\n",
    "#### I end up with 100 vectors of 1x22 for each condition\n",
    "#### Each bin contains 100 dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decoding_spikes_angles_err(df, size_test=0.1):\n",
    "    #### Input : dataframe with three columns: (spikes, behaviour and beuron label)\n",
    "    ###Take off nans\n",
    "    df = df.loc[df.iloc[:,0]<9999]\n",
    "    df.columns=['spikes', 'beh', 'neuron']\n",
    "    neuron_means=[]\n",
    "    ### Train and test on the same neuron --> append the error of each neuron\n",
    "    pop_err=[]\n",
    "    \n",
    "    for Neur in df.neuron.unique():\n",
    "        ### same neuron 5 times --> mean value\n",
    "        neur_err=[]\n",
    "        for rep in range(0,5):\n",
    "            spikes_train, spikes_test, beh_train, beh_test = train_test_split(df.groupby('neuron').get_group(Neur)['spikes'],\n",
    "                                                                              df.groupby('neuron').get_group(Neur)['beh'],\n",
    "                                                                              test_size=size_test)  \n",
    "\n",
    "            ######## Trainning #########\n",
    "            ## X matrix (intercept and spikes)\n",
    "            X = np.column_stack([np.ones(np.shape(spikes_train)[0]),spikes_train])\n",
    "            ## Y (sinus and cos)\n",
    "            sinus =np.sin([np.radians(np.array(beh_train)[i]) for i in range(0, len(beh_train))])\n",
    "            cosinus = np.cos([np.radians(np.array(beh_train)[i]) for i in range(0, len(beh_train))])\n",
    "            Y = np.column_stack([cosinus, sinus])\n",
    "            ### one OLS for sin and cos: output: beta of intercetp and bea of spikes (two B intercepts and 2 B for spikes )\n",
    "            model = sm.OLS(Y, X)\n",
    "            ##train the model\n",
    "            fit=model.fit()\n",
    "\n",
    "            ######### Testing ###########\n",
    "            X = np.column_stack([np.ones(np.shape(spikes_test)[0]),spikes_test])\n",
    "            p = fit.predict(X)\n",
    "            x = p[:,0]\n",
    "            y = p[:,1]\n",
    "            #####\n",
    "            ##### Error --> take the resulting vector in sin/cos space\n",
    "            ### from sin and cos get the angle (-pi, pi)\n",
    "            #pred_angle = [ np.degrees(np.arctan2(y[i], x[i]) + np.pi) for i in range(0, len(y))]\n",
    "            pred_angle = [ np.degrees(np.arctan2(y[i], x[i])) for i in range(0, len(y))]\n",
    "            for i in range(0, len(pred_angle)):\n",
    "                if pred_angle[i]<0:\n",
    "                    pred_angle[i]=360+pred_angle[i]\n",
    "            ##\n",
    "            error=[ circdist(beh_test[i], pred_angle[i]) for i in range(0, len(pred_angle))]\n",
    "\n",
    "            #low_value --> predicted positionns close to real\n",
    "            neur_err.append(np.mean(error))\n",
    "            ####\n",
    "        \n",
    "        #####       \n",
    "        pop_err.append(np.mean(neur_err))\n",
    "        ####\n",
    "    \n",
    "    return np.mean(pop_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Distractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conditions_titles = ['LIP_0_d', 'LIP_100_d', 'LIP_200_d', 'LIP_800_d', 'DLPFC_0_d', 'DLPFC_100_d', 'DLPFC_200_d', 'DLPFC_800_d']\n",
    "Conditions = [LIP_0_d, LIP_100_d, LIP_200_d, LIP_800_d, DLPFC_0_d, DLPFC_100_d, DLPFC_200_d, DLPFC_800_d]\n",
    "\n",
    "conditions_shuff=[]\n",
    "times_shuff=[[] for N in range(0, 100)]\n",
    "\n",
    "\n",
    "for cond in range(0,8):\n",
    "    times_shuff=[[] for N in range(0, 100)]\n",
    "    for N in range(0,100):\n",
    "        print('d', cond, N)\n",
    "        shuff=Conditions[cond].copy()\n",
    "        a = np.roll(shuff[29].values, N+1)\n",
    "        shuff[28]=a\n",
    "        for time in range(0, 22):\n",
    "            df = shuff[[time, 29, 33]]\n",
    "            times_shuff[N].append(decoding_spikes_angles_err(df))\n",
    "    \n",
    "    ##\n",
    "    conditions_shuff.append(times_shuff)\n",
    "    T = pd.DataFrame(conditions_shuff[cond])\n",
    "    sns.pointplot(data=T, label=Conditions_titles[cond])\n",
    "    \n",
    "    \n",
    "## it was done in two times (0-18, 18-22)\n",
    "#os.chdir('C:\\\\Users\\\\David\\\\Dropbox\\\\IDIBAPS\\\\Distractor_neurons\\\\Shuffle')\n",
    "os.chdir('/home/david/Desktop/IDIBAPS/Gottlib/Shuffle')\n",
    "\n",
    "np.save('Shuffle_conditions_d', np.array(conditions_shuff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conditions_titles = ['LIP_0', 'LIP_100', 'LIP_200', 'LIP_800', 'DLPFC_0', 'DLPFC_100', 'DLPFC_200', 'DLPFC_800']\n",
    "Conditions = [LIP_0, LIP_100, LIP_200, LIP_800, DLPFC_0, DLPFC_100, DLPFC_200, DLPFC_800]\n",
    "\n",
    "conditions_shuff=[]\n",
    "times_shuff=[[] for N in range(0, 100)]\n",
    "\n",
    "\n",
    "for cond in range(0,8):    \n",
    "    times_shuff=[[] for N in range(0, 100)]\n",
    "    for N in range(0,100):\n",
    "        print('t', cond, N)\n",
    "        shuff=Conditions[cond].copy()\n",
    "        a = np.roll(shuff[28].values, N+1)\n",
    "        shuff[28]=a\n",
    "        for time in range(0, 22):\n",
    "            df = shuff[[time,28, 33]]\n",
    "            times_shuff[N].append(decoding_spikes_angles_err(df))\n",
    "    \n",
    "    ##\n",
    "    conditions_shuff.append(times_shuff)\n",
    "    T = pd.DataFrame(conditions_shuff[cond])\n",
    "    sns.pointplot(data=T, label=Conditions_titles[cond])\n",
    "    \n",
    "    \n",
    "## it was done in two times (0-18, 18-22)\n",
    "#os.chdir('C:\\\\Users\\\\David\\\\Dropbox\\\\IDIBAPS\\\\Distractor_neurons\\\\Shuffle')\n",
    "os.chdir('/home/david/Desktop/IDIBAPS/Gottlib/Shuffle')\n",
    "\n",
    "np.save('Shuffle_conditions', np.array(conditions_shuff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot target\n",
    "shuffle_conditions = np.load('Shuffle_conditions.npy')\n",
    "Colors=['b', 'y', 'g', 'k',   'r', 'cyan', 'orange', 'grey']\n",
    "print(Conditions_titles)\n",
    "\n",
    "for i in range(0,8):\n",
    "    sns.pointplot(data=shuffle_conditions[i], color=Colors[i], label=Conditions_titles[i], legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot distractor\n",
    "shuffle_conditions_d = np.load('Shuffle_conditions_d.npy')\n",
    "Colors=['b', 'y', 'g', 'k',   'r', 'cyan', 'orange', 'grey']\n",
    "print(Conditions_titles)\n",
    "\n",
    "for i in range(0,8):\n",
    "    sns.pointplot(data=shuffle_conditions_d[i], color=Colors[i], label=Conditions_titles[i], legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
