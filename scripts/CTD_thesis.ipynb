{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from linares_plot import *\n",
    "\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "from mlxtend.evaluate import permutation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\David\\\\Dropbox\\\\IDIBAPS\\\\Distractor_neurons\\\\FR_trials')\n",
    "DLPFC_0 = np.load('0_DLPFC.npy')\n",
    "DLPFC_100 = np.load('100_DLPFC.npy')\n",
    "DLPFC_200 = np.load('200_DLPFC.npy')\n",
    "DLPFC_800 = np.load('800_DLPFC.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, title):\n",
    "    ax = sns.heatmap(data,vmin=50, vmax=90, cmap= 'viridis_r',\n",
    "                    cbar_kws={\"shrink\": .82, 'ticks' : [50, 70, 90], 'label': 'error ($^\\circ$)'}) ##sns.cm.rocket_r\n",
    "    ax.invert_yaxis()\n",
    "    ax.figure.axes[-1].yaxis.label.set_size(15)\n",
    "    plt.gca().set_ylabel('train')\n",
    "    plt.gca().set_xlabel('test')\n",
    "    plt.gca().set_title(title)\n",
    "    plt.gca().set_xticks([0,5,10,15,20])\n",
    "    plt.gca().set_xticklabels([0,5,10,15,20])\n",
    "    plt.gca().set_yticks([0,5,10,15,20])\n",
    "    plt.gca().set_yticklabels([0,5,10,15,20])\n",
    "    plt.show(block=False)\n",
    "    \n",
    "\n",
    "def heatmap_black_white(data, title):\n",
    "    ax = sns.heatmap(data,vmin=0, vmax=1, cmap= 'gray_r',\n",
    "                    cbar_kws={\"shrink\": .82, 'ticks' : [0,1], 'label': 'p<0.05'}) ##sns.cm.rocket_r\n",
    "    ax.invert_yaxis()\n",
    "    ax.figure.axes[-1].yaxis.label.set_size(15)\n",
    "    plt.gca().set_ylabel('train')\n",
    "    plt.gca().set_xlabel('test')\n",
    "    plt.gca().set_title(title)\n",
    "    plt.gca().set_xticks([0,5,10,15,20])\n",
    "    plt.gca().set_xticklabels([0,5,10,15,20])\n",
    "    plt.gca().set_yticks([0,5,10,15,20])\n",
    "    plt.gca().set_yticklabels([0,5,10,15,20])\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    \n",
    "def circdist(a1,a2):\n",
    "    ## Returns the minimal distance in angles between to angles \n",
    "    op1=abs(a2-a1)\n",
    "    angs=[a1,a2]\n",
    "    op2=min(angs)+(360-max(angs))\n",
    "    options=[op1,op2]\n",
    "    return min(options)\n",
    "\n",
    "\n",
    "def decoder_tr_ts(df_train, df_test, splits=10, percentage_training=0.8, cross_val=True):\n",
    "    #### Input : dataframe with three columns: (spikes, behaviour and neuron label)\n",
    "    df_train.columns=['firing', 'beh', 'neuron']\n",
    "    df_test.columns=['firing', 'beh', 'neuron']    \n",
    "    ######\n",
    "    ######## Cross validation ########\n",
    "    ######## different lengths of taringn and testing #####\n",
    "    errors_splits=[]\n",
    "    options_train = np.arange(0, len(df_train))\n",
    "    options_test = np.arange(0, len(df_test))\n",
    "    for s in range(splits):\n",
    "        # training\n",
    "        trials_train = random.sample(list(options_train), int(percentage_training*len(options_train)))\n",
    "        X_train = df_train.iloc[trials_train].firing.values\n",
    "        y_train = df_train.iloc[trials_train].beh.values\n",
    "        #\n",
    "        if cross_val==True: ##same number of trials per neuron\n",
    "            trials_test = list(set(options_train) - set(trials_train))\n",
    "            X_test = df_test.iloc[trials_test].firing.values ## the trials not used for training and the rest\n",
    "            y_test = df_test.iloc[trials_test].beh.values\n",
    "        else:\n",
    "            if len(options_train) == len(options_test):\n",
    "                trials_test = list(set(options_train) - set(trials_train))\n",
    "                X_test = df_test.iloc[trials_test].firing.values ## the trials not used for training and the rest\n",
    "                y_test = df_test.iloc[trials_test].beh.values\n",
    "            else:\n",
    "                trials_test= random.sample(list(options_test), int((1-percentage_training)*len(options_test)))\n",
    "                X_test = df_test.iloc[trials_test].firing.values ## the trials not used for training and the rest\n",
    "                y_test = df_test.iloc[trials_test].beh.values\n",
    "            \n",
    "        ######## Trainning #########\n",
    "        ## X matrix (intercept and spikes)\n",
    "        X = np.column_stack([np.ones(np.shape(X_train)[0]), X_train])\n",
    "        X = np.array(X, dtype=float) \n",
    "        ## Y (sinus and cos)\n",
    "        sinus =np.sin([np.radians(np.array(y_train)[i]) for i in range(0, len(y_train))])\n",
    "        cosinus = np.cos([np.radians(np.array(y_train)[i]) for i in range(0, len(y_train))])\n",
    "        Y = np.column_stack([cosinus, sinus])\n",
    "        ### one OLS for sin and cos: output: beta of intercetp and bea of spikes (two B intercepts and 2 B for spikes )\n",
    "        model = sm.OLS(Y, X)\n",
    "        ##train the model\n",
    "        fit=model.fit()\n",
    "        ######### Testing ###########\n",
    "        X = np.column_stack([np.ones(np.shape(X_test)[0]),X_test])\n",
    "        p = fit.predict(X)\n",
    "        x = p[:,0]\n",
    "        y = p[:,1]\n",
    "        #####\n",
    "        ##### Error --> take the resulting vector in sin/cos space\n",
    "        ### from sin and cos get the angle (-pi, pi)\n",
    "        #pred_angle = [ np.degrees(np.arctan2(y[i], x[i]) + np.pi) for i in range(0, len(y))]\n",
    "        pred_angle = [ np.degrees(np.arctan2(y[i], x[i])) for i in range(0, len(y))]\n",
    "        for i in range(0, len(pred_angle)):\n",
    "            if pred_angle[i]<0:\n",
    "                pred_angle[i]=360+pred_angle[i]\n",
    "        ##\n",
    "        #\n",
    "        #print(beh_test)\n",
    "        error_trial=[ circdist(y_test[i], pred_angle[i]) for i in range(0, len(pred_angle))]\n",
    "        mean_error = np.round(np.mean(error_trial),2)\n",
    "        errors_splits.append(mean_error)\n",
    "    ##\n",
    "    ## mean of all the splits\n",
    "    mean_error = round(np.mean(errors_splits),2)\n",
    "\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "63\n",
      "1367701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367802\n",
      "1367903\n",
      "1369702\n"
     ]
    }
   ],
   "source": [
    "Conditions_titles = ['DLPFC_0', 'DLPFC_100', 'DLPFC_200', 'DLPFC_800']\n",
    "Conditions = [DLPFC_0, DLPFC_100, DLPFC_200, DLPFC_800]\n",
    "\n",
    "shuffled_neurons = [ [] for i in range(len(Conditions_titles)) ]\n",
    "\n",
    "for cond in range(0,len(Conditions_titles)): #8  \n",
    "    print(cond)\n",
    "    shuff = Conditions[cond]\n",
    "    #shuff = shuff[:200, :]\n",
    "    print(len(np.unique(shuff[:, 23])))\n",
    "    for Neuron in np.unique(shuff[:, 23]):\n",
    "        print(Neuron)\n",
    "        shuff = pd.DataFrame(shuff)\n",
    "        df_neuron = shuff.loc[shuff[23] == Neuron]\n",
    "        shuffled_ = np.zeros((22,22))\n",
    "        for idx_training, training_time in enumerate(range(1, 23)):\n",
    "            #print(training_time)\n",
    "            df_train = df_neuron[[training_time, 0, 23]]\n",
    "            df_train.columns=['rate', 'angle', 'neuron']\n",
    "            df_train = df_train.dropna()\n",
    "            for idx_testing, testing_time in enumerate(range(1, 23)):\n",
    "                df_test = df_neuron[[testing_time, 0, 23]]\n",
    "                df_test.columns=['rate', 'angle', 'neuron']\n",
    "                ###\n",
    "                beh_values = df_test.angle.values.copy()\n",
    "                np.random.shuffle(beh_values)\n",
    "                df_test['angle'] = beh_values\n",
    "                df_test = df_test.dropna()\n",
    "                ####\n",
    "                if training_time==testing_time :\n",
    "                    cross_validation=True\n",
    "                else:\n",
    "                    cross_validation=False\n",
    "                err_ = decoder_tr_ts(df_train, df_test, splits=5, percentage_training=0.8, cross_val=cross_validation)\n",
    "                shuffled_[idx_training, idx_testing] =err_\n",
    "                #\n",
    "            #\n",
    "        shuffled_neurons[cond].append(shuffled_)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(shuffled_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, cond in  enumerate(['DLPFC_0', 'DLPFC_100', 'DLPFC_200', 'DLPFC_800']):\n",
    "    H = [pd.DataFrame(shuffled_neurons[idx][x]) for x in range(len(shuffled_neurons[idx]))]\n",
    "    H_mean = pd.concat(H).groupby(level=0).mean()\n",
    "    heatmap(H_mean, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(shuffled_neurons[0])\n",
    "path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_100.npy'\n",
    "np.save(path_save, A)\n",
    "\n",
    "A = np.array(shuffled_neurons[1])\n",
    "path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_200.npy'\n",
    "np.save(path_save, A)\n",
    "\n",
    "A = np.array(shuffled_neurons[2])\n",
    "path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_300.npy'\n",
    "np.save(path_save, A)\n",
    "\n",
    "A = np.array(shuffled_neurons[3])\n",
    "path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_900.npy'\n",
    "np.save(path_save, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_100.xlsx'\n",
    "\n",
    "# writer = pd.ExcelWriter(path_save)\n",
    "# for idx, neuron_name in  enumerate(range(0, len(shuffled_neurons[0]))):\n",
    "#     hm_ = pd.DataFrame(shuffled_neurons[0][idx])\n",
    "#     hm_.to_excel(writer, sheet_name=str(neuron_name)) #each dataframe in a excel sheet\n",
    "\n",
    "# writer.save()   #save reconstructions (heatmaps)\n",
    "\n",
    "# path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_200.xlsx'\n",
    "\n",
    "# writer = pd.ExcelWriter(path_save)\n",
    "# for idx, neuron_name in  enumerate(range(0, len(shuffled_neurons[1]))):\n",
    "#     hm_ = pd.DataFrame(shuffled_neurons[1][idx])\n",
    "#     hm_.to_excel(writer, sheet_name=str(neuron_name)) #each dataframe in a excel sheet\n",
    "\n",
    "# writer.save()   #save reconstructions (heatmaps)\n",
    "\n",
    "# path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_300.xlsx'\n",
    "\n",
    "# writer = pd.ExcelWriter(path_save)\n",
    "# for idx, neuron_name in  enumerate(range(0, len(shuffled_neurons[2]))):\n",
    "#     hm_ = pd.DataFrame(shuffled_neurons[2][idx])\n",
    "#     hm_.to_excel(writer, sheet_name=str(neuron_name)) #each dataframe in a excel sheet\n",
    "\n",
    "# writer.save()   #save reconstructions (heatmaps)\n",
    "\n",
    "# path_save = 'C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_900.xlsx'\n",
    "\n",
    "# writer = pd.ExcelWriter(path_save)\n",
    "# for idx, neuron_name in  enumerate(range(0, len(shuffled_neurons[3]))):\n",
    "#     hm_ = pd.DataFrame(shuffled_neurons[3][idx])\n",
    "#     hm_.to_excel(writer, sheet_name=str(neuron_name)) #each dataframe in a excel sheet\n",
    "\n",
    "# writer.save()   #save reconstructions (heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Significance vs shuffle of the heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\David\\\\Dropbox\\\\IDIBAPS\\\\Distractor_neurons')\n",
    "cd_DLPFC_hm = np.load('cd_DLPFC_hm.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFC_0 =  cd_DLPFC_hm[0]\n",
    "heatmap(PFC_0, 'DLPFC: TDOA=100ms')\n",
    "\n",
    "\n",
    "B = np.load('C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_100.npy')\n",
    "np.shape(B)\n",
    "\n",
    "sign_matrix = np.ones((22,22))\n",
    "for training_time in range(22):\n",
    "    for testing_time in range(22):\n",
    "        shuffle_distr = [B[x][training_time, testing_time] for x in range(len(B))]\n",
    "        signal = PFC_0[training_time, testing_time]\n",
    "        p_value = permutation_test([signal], shuffle_distr, method='approximate', num_rounds=100, seed=0)\n",
    "        sign_matrix[training_time, testing_time] = p_value\n",
    "        \n",
    "\n",
    "sign_matrix_1_0 = sign_matrix<0.05 *1\n",
    "heatmap_black_white(sign_matrix_1_0, 'DLPFC: TDOA=100ms')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFC_0 =  cd_DLPFC_hm[1]\n",
    "heatmap(PFC_0, 'DLPFC: TDOA=200ms')\n",
    "\n",
    "\n",
    "B = np.load('C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_200.npy')\n",
    "np.shape(B)\n",
    "\n",
    "sign_matrix = np.ones((22,22))\n",
    "for training_time in range(22):\n",
    "    for testing_time in range(22):\n",
    "        shuffle_distr = [B[x][training_time, testing_time] for x in range(len(B))]\n",
    "        signal = PFC_0[training_time, testing_time]\n",
    "        p_value = permutation_test([signal], shuffle_distr, method='approximate', num_rounds=100, seed=0)\n",
    "        sign_matrix[training_time, testing_time] = p_value\n",
    "        \n",
    "\n",
    "sign_matrix_1_0 = sign_matrix<0.05 *1\n",
    "heatmap_black_white(sign_matrix_1_0, 'DLPFC: TDOA=200ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFC_0 =  cd_DLPFC_hm[2]\n",
    "heatmap(PFC_0, 'DLPFC: TDOA=300ms')\n",
    "\n",
    "\n",
    "B = np.load('C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_300.npy')\n",
    "np.shape(B)\n",
    "\n",
    "sign_matrix = np.ones((22,22))\n",
    "for training_time in range(22):\n",
    "    for testing_time in range(22):\n",
    "        shuffle_distr = [B[x][training_time, testing_time] for x in range(len(B))]\n",
    "        signal = PFC_0[training_time, testing_time]\n",
    "        p_value = permutation_test([signal], shuffle_distr, method='approximate', num_rounds=100, seed=0)\n",
    "        sign_matrix[training_time, testing_time] = p_value\n",
    "        \n",
    "\n",
    "sign_matrix_1_0 = sign_matrix<0.05 *1\n",
    "heatmap_black_white(sign_matrix_1_0, 'DLPFC: TDOA=300ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFC_0 =  cd_DLPFC_hm[3]\n",
    "heatmap(PFC_0, 'DLPFC: TDOA=900ms')\n",
    "\n",
    "\n",
    "B = np.load('C:\\\\Users\\\\David\\\\Desktop\\\\shuffle_HM_DLPFC_900.npy')\n",
    "np.shape(B)\n",
    "\n",
    "sign_matrix = np.ones((22,22))\n",
    "for training_time in range(22):\n",
    "    for testing_time in range(22):\n",
    "        shuffle_distr = [B[x][training_time, testing_time] for x in range(len(B))]\n",
    "        signal = PFC_0[training_time, testing_time]\n",
    "        p_value = permutation_test([signal], shuffle_distr, method='approximate', num_rounds=100, seed=0)\n",
    "        sign_matrix[training_time, testing_time] = p_value\n",
    "        \n",
    "\n",
    "sign_matrix_1_0 = sign_matrix<0.05 *1\n",
    "heatmap_black_white(sign_matrix_1_0, 'DLPFC: TDOA=900ms')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
